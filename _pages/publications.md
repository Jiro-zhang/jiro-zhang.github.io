---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---


<table style="width:100%;border:None;border-spacing:0px;border-collapse:separate;margin-right:0;margin-left:0;font-size:0.9em;">
  <tr>
    <td style="padding:10px;width:20%;vertical-align:middle;border-right:none;border-bottom:none;">
      <a href="https://github.com/Jiro-zhang/jiro-zhang.github.io/blob/main/images/EnergyMoGen.gif">
      <img src='../images/EnergyMoGen.gif' width="200">
      </a>
    </td>
    <td style="padding:5px;width:80%;vertical-align:middle;border-right:none;border-bottom:none;">
      <b>EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space</b>, 
      <br>
      <a href="https://jiro-zhang.github.io/">Jianrong Zhang</a>, 
      <a href="https://hehefan.github.io/">Hehe Fan<sup>+</sup></a>,
      and
      <a href="https://scholar.google.com/citations?user=RMSuNFwAAAAJ&hl=en">Yi Yang</a>.
      <br>
      <i>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR 2025 Highlight</b>)</i>.
      <br>
      [<a href="https://jiro-zhang.github.io/EnergyMoGen/">Project page</a>]
      [<a href="https://arxiv.org/abs/2412.14706">arXiv</a>]
    </td>
  </tr>
</table>


<table style="width:100%;border:None;border-spacing:0px;border-collapse:separate;margin-right:0;margin-left:0;font-size:0.9em;">
  <tr>
    <td style="padding:10px;width:20%;vertical-align:middle;border-right:none;border-bottom:none;">
      <a href="https://github.com/Jiro-zhang/jiro-zhang.github.io/blob/main/images/HST-Net.gif">
      <img src='../images/HST-Net.gif' width="200">
      </a>
    </td>
    <td style="padding:5px;width:80%;vertical-align:middle;border-right:none;border-bottom:none;">
      <b>Hand-Centric Motion Refinement for 3D Hand-Object Interaction via Hierarchical Spatial-Temporal Modeling</b>, 
      <br>
      Yuze Hao,
      <a href="https://jiro-zhang.github.io/">Jianrong Zhang</a>, 
      <a href="https://scholar.google.com/citations?user=q8Mfr6AAAAAJ&hl=en">Tao Zhuo</a>, 
      Fuan Wen, 
      and
      <a href="https://hehefan.github.io/">Hehe Fan<sup>+</sup></a>.
      <br>
      <i>In Proceedings of the AAAI Conference on Artificial Intelligence (<b>AAAI 2024</b>)</i>.
      <br>
      [<a href="https://arxiv.org/abs/2401.15987">arXiv</a>]
      [<a href="https://github.com/Holiday888/HST-Net">Code</a>]
    </td>
  </tr>
</table>


<table style="width:100%;border:None;border-spacing:0px;border-collapse:separate;margin-right:0;margin-left:0;font-size:0.9em;">
  <tr>
    <td style="padding:10px;width:20%;vertical-align:middle;border-right:none;border-bottom:none;">
      <a href="https://github.com/Jiro-zhang/jiro-zhang.github.io/blob/main/images/T2M-GPT.gif">
      <img src='../images/T2M-GPT.gif' width="200">
      </a>
    </td>
    <td style="padding:5px;width:80%;vertical-align:middle;border-right:none;border-bottom:none;">
      <b>T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete Representations</b>, 
      <br>
      <a href="https://jiro-zhang.github.io/">Jianrong Zhang*</a>, 
      Yangsong Zhang*, 
      <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>,
      <a href="https://scholar.google.com/citations?user=o31BPFsAAAAJ&hl=en">Shaoli Huang</a>,
      <a href="https://yzhang2016.github.io/">Yong Zhang</a>,
      Hongwei Zhao, 
      Hongtao Lu, 
      and
      <a href="https://xishen0220.github.io/">Xi Shen<sup>+</sup></a>.
      <br>
      <i>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR 2023</b>)</i>.
      <br>
      [<a href="https://mael-zys.github.io/T2M-GPT/">Project page</a>]
      [<a href="https://github.com/Mael-zys/T2M-GPT/blob/main/T2M-GPT.pdf">PDF</a>]
      [<a href="https://github.com/Mael-zys/T2M-GPT">Code</a>]
      [<a href="https://arxiv.org/abs/2301.06052">arXiv</a>]
      [<a href="https://colab.research.google.com/drive/1Vy69w2q2d-Hg19F-KibqG0FRdpSj3L4O?usp=sharing">Colab</a>]
      [<a href="https://huggingface.co/spaces/vumichien/generate_human_motion">Huggingface</a>]
    </td>
  </tr>
</table>

<table style="width:100%;border:None;border-spacing:0px;border-collapse:separate;margin-right:0;margin-left:0;font-size:0.9em;">
  <tr>
    <td style="padding:10px;width:20%;vertical-align:middle;border-right:none;border-bottom:none;">
      <a href="https://github.com/Jiro-zhang/jiro-zhang.github.io/blob/main/images/region_arch.png">
      <img src='../images/DeS4.jpg' width="200">
      </a>
    </td>
    <td style="padding:5px;width:80%;vertical-align:middle;border-right:none;border-bottom:none;">
      <b>Decoupling with Entropy-based Equalization for Semi-Supervised Semantic Segmentation</b>, 
      <br>
      <a href="https://scholar.google.com/citations?user=1rYvBtEAAAAJ&hl=zh-CN">Chuanghao Ding*</a>,
      <a href="https://jiro-zhang.github.io/">Jianrong Zhang*</a>,
      <a href="https://henghuiding.github.io/">Henghui Ding*</a>, 
      Hongwei Zhao<sup>+</sup>, 
      Zhihui Wang,
      Tengfei Xing<sup>+</sup>,
      and 
      Runbo Hu.
      <br>
      <i>In Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence (<b>IJCAI 2023</b>)</i>. 
      <br>
      [<a href="https://www.ijcai.org/proceedings/2023/0074.pdf">PDF</a>]
    </td>
  </tr>
</table>


<table style="width:100%;border:None;border-spacing:0px;border-collapse:separate;margin-right:0;margin-left:0;font-size:0.9em;">
  <tr>
    <td style="padding:10px;width:20%;vertical-align:middle;border-right:none;border-bottom:none;">
      <a href="https://github.com/Jiro-zhang/jiro-zhang.github.io/blob/main/images/region_arch.png">
      <img src='../images/region_arch.png' width="200">
      </a>
    </td>
    <td style="padding:5px;width:80%;vertical-align:middle;border-right:none;border-bottom:none;">
      <b>Region-level Contrastive and Consistency Learning for Semi-Supervised Semantic Segmentation</b>, 
      <br>
      <a href="https://jiro-zhang.github.io/">Jianrong Zhang*</a>,
      <a href="https://scholar.google.com/citations?user=FHdkcWsAAAAJ&hl=en">Tianyi Wu*</a>, 
      <a href="https://scholar.google.com/citations?user=1rYvBtEAAAAJ&hl=zh-CN">Chuanghao Ding*</a>,
      Hongwei Zhao, 
      and
      <a href="https://scholar.google.com/citations?user=f2Y5nygAAAAJ&hl=zh-CN">Guodong Guo<sup>+</sup></a>.
      <br>
      <i>In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence (<b>IJCAI 2022</b>, Long oral presentation)</i>. 
      <br>
      [<a href="https://www.ijcai.org/proceedings/2022/0226.pdf">PDF</a>]
      [<a href="https://arxiv.org/abs/2204.13314">arXiv</a>]
    </td>
  </tr>
</table>

